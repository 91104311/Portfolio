{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove duplicates rows including reversal transactionType and multi-swipe transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()\n",
    "\n",
    "df2=df2.loc[df2.transactionType!='REVERSAL']\n",
    "df2['MultiSwipe'] = (df2.sort_values(['transactionDateTime'])\n",
    "                       .groupby(['customerId','merchantName', 'transactionAmount','transactionType'], sort=False)['transactionDateTime']\n",
    "                       .diff()\n",
    "                       .dt.total_seconds()\n",
    "                       .lt(180))\n",
    "df2=df2.loc[dft.MultiSwipe==False]\n",
    "df2=df2.reset_index(drop=True)\n",
    "\n",
    "df3=df2.copy()\n",
    "\n",
    "#pd.reset_option(“max_columns”)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then we caculate percentage of Null values in each column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accountNumber               0.00\n",
       "customerId                  0.00\n",
       "creditLimit                 0.00\n",
       "availableMoney              0.00\n",
       "transactionDateTime         0.00\n",
       "transactionAmount           0.00\n",
       "merchantName                0.00\n",
       "acqCountry                  0.58\n",
       "merchantCountryCode         0.09\n",
       "posEntryMode                0.51\n",
       "posConditionCode            0.05\n",
       "merchantCategoryCode        0.00\n",
       "currentExpDate              0.00\n",
       "accountOpenDate             0.00\n",
       "dateOfLastAddressChange     0.00\n",
       "cardCVV                     0.00\n",
       "enteredCVV                  0.00\n",
       "cardLast4Digits             0.00\n",
       "transactionType             0.09\n",
       "currentBalance              0.00\n",
       "cardPresent                 0.00\n",
       "expirationDateKeyInMatch    0.00\n",
       "isFraud                     0.00\n",
       "MultiSwipe                  0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df3.isnull().sum()*100/len(df3),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since less than 0.6% of rows have null values, we removed those rows from dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.dropna(inplace=True)\n",
    "\n",
    "#df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Irrelevant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove these columns ('accountNumber','customerId','MultiSwipe','cardLast4Digits','currentBalance') because they do not affect our final prediction. \n",
    "Note that currentBalance=creditLimit-availableMoney and we already have \"credit limit\" and \"available money\" in our dataset, so we do not need \"current balance\" anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.drop(['accountNumber','customerId','MultiSwipe','cardLast4Digits','currentBalance','merchantName'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a new feature as CVV_correct to see if a customer enters right CVV code. We can use this one later for our fraud detection model.Then we remove 'cardCVV' and 'enteredCVV' since we do not need them anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df3.copy()\n",
    "\n",
    "df4['CVV_correct'] = df4['cardCVV'] == df4['enteredCVV']\n",
    "df4.drop(['cardCVV','enteredCVV'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to converted these 3 date columns to number as follows:\n",
    "    - accountOpenDate_days: Number of days since its opening\n",
    "    - dateOfLastAddressChange_days: Number of days since last address changing\n",
    "    - currentExpDate_days: Number of days until expiration date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['accountOpenDate'] = pd.to_datetime(df4['accountOpenDate'])\n",
    "df4['dateOfLastAddressChange'] = pd.to_datetime(df4['dateOfLastAddressChange'])\n",
    "df4['currentExpDate'] = pd.to_datetime(df4['currentExpDate'])\n",
    "\n",
    "df4['accountOpenDate_days']=pd.Timestamp.now().normalize()-df4['accountOpenDate']\n",
    "df4['dateOfLastAddressChange_days']=pd.Timestamp.now().normalize()-df4['dateOfLastAddressChange']\n",
    "df4['currentExpDate_days']=df4['currentExpDate']-pd.Timestamp.now().normalize()\n",
    "\n",
    "df4['accountOpenDate_days'] = df4['accountOpenDate_days'].astype(int)\n",
    "df4['accountOpenDate_days']=df4['accountOpenDate_days']/(24*3600*(10**9))\n",
    "df4['dateOfLastAddressChange_days'] = df4['dateOfLastAddressChange_days'].astype(int)\n",
    "df4['dateOfLastAddressChange_days']=df4['dateOfLastAddressChange_days']/(24*3600*(10**9))\n",
    "df4['currentExpDate_days'] = df4['currentExpDate_days'].astype(int)\n",
    "df4['currentExpDate_days']=df4['currentExpDate_days']/(24*3600*(10**9))\n",
    "\n",
    "df4.drop(['accountOpenDate','dateOfLastAddressChange','currentExpDate'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Regarding 'transactionDateTime' column, we extracted 'day' and 'hour' to address the effect of transaction time on fraud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['tran_day'] = df4['transactionDateTime'].dt.day\n",
    "df4['tran_hour'] = df4['transactionDateTime'].dt.hour\n",
    "df4.drop(['transactionDateTime'],axis=1,inplace=True)\n",
    "\n",
    "#df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert bool to int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We converted bool columns ('cardPresent','expirationDateKeyInMatch','isFraud','CVV_correct') to 0 and 1 (False=0 and True=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=df4.copy()\n",
    "\n",
    "df5['cardPresent'] = df5['cardPresent'].astype(int)\n",
    "df5['expirationDateKeyInMatch'] = df5['expirationDateKeyInMatch'].astype(int)\n",
    "df5['isFraud'] = df5['isFraud'].astype(int)\n",
    "df5['CVV_correct'] = df5['CVV_correct'].astype(int)\n",
    "\n",
    "#df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df5.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. acqCountry Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US     742228\n",
       "MEX      2997\n",
       "CAN      2311\n",
       "PR       1482\n",
       "Name: acqCountry, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6['acqCountry'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we use One-hot Encoding for this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.concat([df6,pd.get_dummies(df6['acqCountry'], prefix='acqCountry')], axis=1).drop(['acqCountry'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. merchantCountryCode Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US     742230\n",
       "MEX      2993\n",
       "CAN      2305\n",
       "PR       1490\n",
       "Name: merchantCountryCode, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6['merchantCountryCode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we use One-hot Encoding for this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.concat([df6,pd.get_dummies(df6['merchantCountryCode'], prefix='merchantCountryCode')], axis=1).drop(['merchantCountryCode'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. posEntryMode Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "05    301719\n",
       "09    226279\n",
       "02    187588\n",
       "90     18775\n",
       "80     14657\n",
       "Name: posEntryMode, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6['posEntryMode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we use One-hot Encoding for this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.concat([df6,pd.get_dummies(df6['posEntryMode'], prefix='posEntryMode')], axis=1).drop(['posEntryMode'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. posConditionCode Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "01    599165\n",
       "08    142683\n",
       "99      7170\n",
       "Name: posConditionCode, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6['posConditionCode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we use One-hot Encoding for this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.concat([df6,pd.get_dummies(df6['posConditionCode'], prefix='posConditionCode')], axis=1).drop(['posConditionCode'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. merchantCategoryCode Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "online_retail           192037\n",
       "fastfood                106443\n",
       "entertainment            76050\n",
       "food                     71595\n",
       "online_gifts             62914\n",
       "rideshare                48630\n",
       "hotels                   32331\n",
       "fuel                     23631\n",
       "subscriptions            21789\n",
       "auto                     20555\n",
       "health                   18136\n",
       "personal care            17998\n",
       "mobileapps               14787\n",
       "airline                  14581\n",
       "online_subscriptions     10928\n",
       "furniture                 7080\n",
       "food_delivery             6000\n",
       "gym                       2183\n",
       "cable/phone               1350\n",
       "Name: merchantCategoryCode, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6['merchantCategoryCode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we use One-hot Encoding for this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.concat([df6,pd.get_dummies(df6['merchantCategoryCode'], prefix='merchantCategoryCode')], axis=1).drop(['merchantCategoryCode'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before ending feature eng section, we can see for \"ADDRESS_VERIFICATION\" transaction, there are just 112 fraud so in order to prevent biasing the model, we just work with 'PURCHASE' transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19637\n",
       "1      112\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7=df6.loc[df6.transactionType=='ADDRESS_VERIFICATION']\n",
    "df7['isFraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df6.loc[df6.transactionType=='PURCHASE']\n",
    "df6.drop(['transactionType'],axis=1,inplace=True)\n",
    "\n",
    "#df6.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
